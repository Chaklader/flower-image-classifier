# C-5: Implementation and Applications

1. Building Transformer Models in PyTorch
   - Model Components Implementation
   - Attention Block Coding
   - Feedforward Networks
   - Layer Normalization
   - Training and Evaluation Process
2. Decoder-only Architecture
   - GPT-style Models
   - Causal Masking Implementation
   - Autoregressive Property
   - Generation Strategies
   - Applications and Limitations
3. Using Pre-trained Models with Hugging Face
   - Pipeline API Usage
   - Model Selection Guidelines
   - Text Generation Parameters
   - Fine-tuning Pre-trained Models
   - Multi-modal Applications
