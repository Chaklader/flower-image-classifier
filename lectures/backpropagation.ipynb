{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "grader_id": "tpan1eblwvo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done!\n",
      "Well done!\n",
      "Well done!\n",
      "Well done!\n",
      "Change in weights for hidden layer to output layer:\n",
      "[0.00804047 0.00555918]\n",
      "Change in weights for input layer to hidden layer:\n",
      "[[ 1.77005547e-04 -5.11178506e-04]\n",
      " [ 3.54011093e-05 -1.02235701e-04]\n",
      " [-7.08022187e-05  2.04471402e-04]]\n",
      "Well done!\n",
      "Change in weights for hidden layer to output layer:\n",
      "[0.00804047 0.00555918]\n",
      "Change in weights for input layer to hidden layer:\n",
      "[[ 1.77005547e-04 -5.11178506e-04]\n",
      " [ 3.54011093e-05 -1.02235701e-04]\n",
      " [-7.08022187e-05  2.04471402e-04]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "x = np.array([0.5, 0.1, -0.2])\n",
    "\n",
    "target = 0.6\n",
    "learnrate = 0.5\n",
    "\n",
    "weights_input_hidden = np.array([[0.5, -0.6],\n",
    "                                 [0.1, -0.2],\n",
    "                                 [0.1, 0.7]])\n",
    "\n",
    "weights_hidden_output = np.array([0.1, -0.3])\n",
    "\n",
    "## Forward pass\n",
    "hidden_layer_input = np.dot(x, weights_input_hidden)\n",
    "hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "output = sigmoid(output_layer_in)\n",
    "\n",
    "## Backwards pass\n",
    "\n",
    "# Calculate output error\n",
    "error = target - output                      # <-- LINE 1\n",
    "\n",
    "### Notebook grading\n",
    "error_answer = target - output\n",
    "\n",
    "if error == error_answer:\n",
    "    print(\"Well done!\")\n",
    "else:\n",
    "    print(\"Try again. Something is wrong in your submission\")\n",
    "\n",
    "# Calculate error term for output layer\n",
    "\n",
    "# output * (1 - output) is the derivative of the sigmoid activation\n",
    "# σ'(z) = σ(z)(1 - σ(z)).\n",
    "# In back-propagation you multiply that derivative by the error coming from\n",
    "# the loss:\n",
    "\n",
    "# error             = (y_true - output)           # ∂L/∂output\n",
    "# output_error_term = error * output * (1 - output) # ∂L/∂z\n",
    "\n",
    "# So output_error_term is not the derivative of the sigmoid by itself; it is the\n",
    "# gradient of the loss with respect to the neuron's pre-activation input z.\n",
    "# In other words, it's the product of:\n",
    "\n",
    "# 1. the derivative of the loss w.r.t. the neuron's output (error), and\n",
    "# 2. the derivative of the sigmoid w.r.t. its input (output * (1-output)).\n",
    "# TODO: Calculate error term for output layer\n",
    "output_error_term = error * output * (1 - output) # <-- LINE 2\n",
    "\n",
    "### Notebook grading\n",
    "\n",
    "del_err_output_answer = error_answer * output * (1 - output)\n",
    "\n",
    "if output_error_term == del_err_output_answer:\n",
    "    print(\"Well done!\")\n",
    "else:\n",
    "    print(\"Try again. Something is wrong in your submission\")\n",
    "\n",
    "\n",
    "# Calculate error term for hidden layer\n",
    "# hidden_error_term = np.dot(output_error_term, weights_hidden_output) * \\\n",
    "#                     hidden_layer_output * (1 - hidden_layer_output)\n",
    "\n",
    "\n",
    "# TODO: Calculate error term for hidden layer\n",
    "hidden_error_term = np.dot(output_error_term, weights_hidden_output) * \\\n",
    "                    hidden_layer_output * (1 - hidden_layer_output) # <-- LINE 3\n",
    "\n",
    "### Notebook grading\n",
    "\n",
    "del_err_hidden_answer = np.dot(del_err_output_answer, weights_hidden_output) * \\\n",
    "                    hidden_layer_output * (1 - hidden_layer_output)\n",
    "\n",
    "test_h = del_err_hidden_answer == hidden_error_term\n",
    "\n",
    "if test_h.all():\n",
    "    print(\"Well done!\")\n",
    "else:\n",
    "    print(\"Try again. Something is wrong in your submission\")\n",
    "\n",
    "# Calculate change in weights for hidden layer to output layer\n",
    "# delta_w_h_o = learnrate  *output_error_term*  hidden_layer_output\n",
    "# TODO: Calculate change in weights for hidden layer to output layer\n",
    "delta_w_h_o = learnrate * output_error_term * hidden_layer_output # <-- LINE 4\n",
    "\n",
    "### Notebook grading\n",
    "delta_w_h_o_answer = learnrate * del_err_output_answer * hidden_layer_output\n",
    "\n",
    "test_w_h_o = delta_w_h_o_answer == delta_w_h_o\n",
    "\n",
    "if test_w_h_o.all():\n",
    "    print(\"Well done!\")\n",
    "else:\n",
    "    print(\"Try again. Something is wrong in your submission\")\n",
    "\n",
    "# Calculate change in weights for input layer to hidden layer\n",
    "# delta_w_i_h = learnrate  *hidden_error_term*  x[:, None]\n",
    "\n",
    "# TODO: Calculate change in weights for input layer to hidden layer\n",
    "delta_w_i_h = learnrate * hidden_error_term * x[:, None] # <-- LINE 5\n",
    "print('Change in weights for hidden layer to output layer:')\n",
    "print(delta_w_h_o)\n",
    "print('Change in weights for input layer to hidden layer:')\n",
    "print(delta_w_i_h)\n",
    "\n",
    "### Notebook grading\n",
    "\n",
    "delta_w_i_h_answer = learnrate * del_err_hidden_answer * x[:, None]\n",
    "\n",
    "\n",
    "test_w_i_h = delta_w_i_h_answer == delta_w_i_h\n",
    "\n",
    "if test_w_i_h.all():\n",
    "    print(\"Well done!\")\n",
    "else:\n",
    "    print(\"Try again. Something is wrong in your submission\")\n",
    "    \n",
    "print('Change in weights for hidden layer to output layer:')\n",
    "print(delta_w_h_o)\n",
    "print('Change in weights for input layer to hidden layer:')\n",
    "print(delta_w_i_h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "grader_id": "qmxtpj5tamp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate error term for output layer\n",
    "output_error_term = error * output * (1 - output)\n",
    "\n",
    "### Notebook grading\n",
    "\n",
    "del_err_output_answer = error_answer * output * (1 - output)\n",
    "\n",
    "if output_error_term == del_err_output_answer:\n",
    "    print(\"Well done!\")\n",
    "else:\n",
    "    print(\"Try again. Something is wrong in your submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "grader_id": "zj3fszdv71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate error term for hidden layer\n",
    "hidden_error_term = np.dot(output_error_term, weights_hidden_output) * \\\n",
    "                    hidden_layer_output * (1 - hidden_layer_output)\n",
    "\n",
    "### Notebook grading\n",
    "\n",
    "del_err_hidden_answer = np.dot(del_err_output_answer, weights_hidden_output) * \\\n",
    "                    hidden_layer_output * (1 - hidden_layer_output)\n",
    "\n",
    "test_h = del_err_hidden_answer == hidden_error_term\n",
    "\n",
    "if test_h.all():\n",
    "    print(\"Well done!\")\n",
    "else:\n",
    "    print(\"Try again. Something is wrong in your submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "grader_id": "69z9t19f1bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate change in weights for hidden layer to output layer\n",
    "delta_w_h_o = learnrate * output_error_term * hidden_layer_output\n",
    "\n",
    "### Notebook grading\n",
    "delta_w_h_o_answer = learnrate * del_err_output_answer * hidden_layer_output\n",
    "\n",
    "test_w_h_o = delta_w_h_o_answer == delta_w_h_o\n",
    "\n",
    "if test_w_h_o.all():\n",
    "    print(\"Well done!\")\n",
    "else:\n",
    "    print(\"Try again. Something is wrong in your submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "grader_id": "qq3jm1wy8mc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in weights for hidden layer to output layer:\n",
      "[0.00804047 0.00555918]\n",
      "Change in weights for input layer to hidden layer:\n",
      "[[ 1.77005547e-04 -5.11178506e-04]\n",
      " [ 3.54011093e-05 -1.02235701e-04]\n",
      " [-7.08022187e-05  2.04471402e-04]]\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate change in weights for input layer to hidden layer\n",
    "delta_w_i_h = learnrate * hidden_error_term * x[:, None]\n",
    "print('Change in weights for hidden layer to output layer:')\n",
    "print(delta_w_h_o)\n",
    "print('Change in weights for input layer to hidden layer:')\n",
    "print(delta_w_i_h)\n",
    "\n",
    "### Notebook grading\n",
    "\n",
    "delta_w_i_h_answer = learnrate * del_err_hidden_answer * x[:, None]\n",
    "\n",
    "\n",
    "test_w_i_h = delta_w_i_h_answer == delta_w_i_h\n",
    "\n",
    "if test_w_i_h.all():\n",
    "    print(\"Well done!\")\n",
    "else:\n",
    "    print(\"Try again. Something is wrong in your submission\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
