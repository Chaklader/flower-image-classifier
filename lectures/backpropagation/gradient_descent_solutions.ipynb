{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Activation (sigmoid) function\n",
    "import numpy as np \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-np.array(x, dtype=float)))\n",
    "\n",
    "# Output (prediction) formula\n",
    "def output_formula(features, weights, bias):\n",
    "    return sigmoid(np.dot(features, weights) + bias)\n",
    "\n",
    "# Error (log-loss) formula\n",
    "def error_formula(y, output):\n",
    "    return - y*np.log(output) - (1 - y) * np.log(1-output)\n",
    "\n",
    "# Gradient descent step\n",
    "def update_weights(x, y, weights, bias, learnrate):\n",
    "    output = output_formula(x, weights, bias)\n",
    "    d_error = y - output\n",
    "    weights += learnrate * d_error * x\n",
    "    bias += learnrate * d_error\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Numerical Example: Binary Classification Learning ######\n",
      "\n",
      "Problem Setup:\n",
      "Classify whether a student passes (1) or fails (0) based on study hours.\n",
      "\n",
      "Student 1: x = [2.], y = 0 (2 hours study, failed)\n",
      "Student 2: x = [8.], y = 1 (8 hours study, passed)\n",
      "\n",
      "Initial Parameters:\n",
      "weights = [0.5], bias = 0.1, learning_rate = 0.1\n",
      "\n",
      "--------------------------------------------------\n",
      "###### Training Step 1: Process Student 1 ######\n",
      "Processing: features = [2.], y = 0\n",
      "\n",
      "1. Forward Pass:\n",
      "   linear_combination = (2.0 * 0.5) + 0.1 = 1.100\n",
      "   output = sigmoid(1.100) = 0.750\n",
      "\n",
      "2. Calculate Error:\n",
      "   error = -0*log(0.750) - (1-0)*log(1-0.750) = 1.387\n",
      "\n",
      "3. Weight Updates:\n",
      "   d_error = 0 - 0.750 = -0.750\n",
      "   new_weights = 0.500 + 0.1 * -0.750 * 2.0 = 0.350\n",
      "   new_bias = 0.100 + 0.1 * -0.750 = 0.025\n",
      "\n",
      "Results After Step 1:\n",
      "weights = [0.350], bias = 0.025\n",
      "--------------------------------------------------\n",
      "###### Training Step 2: Process Student 2 ######\n",
      "Processing: features = [8.], y = 1\n",
      "\n",
      "1. Forward Pass:\n",
      "   linear_combination = (8.0 * 0.350) + 0.025 = 2.825\n",
      "   output = sigmoid(2.825) = 0.944\n",
      "\n",
      "2. Calculate Error:\n",
      "   error = -1*log(0.944) - (1-1)*log(1-0.944) = 0.058\n",
      "\n",
      "3. Weight Updates:\n",
      "   d_error = 1 - 0.944 = 0.056\n",
      "   new_weights = 0.350 + 0.1 * 0.056 * 8.0 = 0.395\n",
      "   new_bias = 0.025 + 0.1 * 0.056 = 0.031\n",
      "\n",
      "Final Results After Step 2:\n",
      "weights = [0.395], bias = 0.031\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Function Definitions ---\n",
    "def sigmoid(x):\n",
    "    \"\"\"Activation (sigmoid) function.\"\"\"\n",
    "    return 1 / (1 + np.exp(-np.array(x, dtype=float)))\n",
    "\n",
    "def output_formula(features, weights, bias):\n",
    "    \"\"\"Output (prediction) formula.\"\"\"\n",
    "    return sigmoid(np.dot(features, weights) + bias)\n",
    "\n",
    "def error_formula(y, output):\n",
    "    \"\"\"Error (log-loss) formula.\"\"\"\n",
    "    return - y*np.log(output) - (1 - y) * np.log(1-output)\n",
    "\n",
    "# --- Initial Setup ---\n",
    "print(\"###### Numerical Example: Binary Classification Learning ######\\n\")\n",
    "print(\"Problem Setup:\")\n",
    "print(\"Classify whether a student passes (1) or fails (0) based on study hours.\\n\")\n",
    "\n",
    "# Training Data\n",
    "student_1_x, student_1_y = np.array([2.0]), 0\n",
    "student_2_x, student_2_y = np.array([8.0]), 1\n",
    "print(f\"Student 1: x = {student_1_x}, y = {student_1_y} (2 hours study, failed)\")\n",
    "print(f\"Student 2: x = {student_2_x}, y = {student_2_y} (8 hours study, passed)\\n\")\n",
    "\n",
    "# Initial Parameters\n",
    "weights = np.array([0.5])\n",
    "bias = 0.1\n",
    "learnrate = 0.1\n",
    "print(\"Initial Parameters:\")\n",
    "print(f\"weights = {weights}, bias = {bias}, learning_rate = {learnrate}\\n\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- Training Step 1: Process Student 1 ---\n",
    "print(\"###### Training Step 1: Process Student 1 ######\")\n",
    "print(f\"Processing: features = {student_1_x}, y = {student_1_y}\\n\")\n",
    "\n",
    "# Forward Pass\n",
    "print(\"1. Forward Pass:\")\n",
    "linear_combination_1 = np.dot(student_1_x, weights) + bias\n",
    "output_1 = sigmoid(linear_combination_1)\n",
    "print(f\"   linear_combination = ({student_1_x[0]} * {weights[0]}) + {bias} = {linear_combination_1:.3f}\")\n",
    "print(f\"   output = sigmoid({linear_combination_1:.3f}) = {output_1:.3f}\\n\")\n",
    "\n",
    "# Calculate Error\n",
    "print(\"2. Calculate Error:\")\n",
    "error_1 = error_formula(student_1_y, output_1)\n",
    "print(f\"   error = -{student_1_y}*log({output_1:.3f}) - (1-{student_1_y})*log(1-{output_1:.3f}) = {error_1:.3f}\\n\")\n",
    "\n",
    "# Weight Updates\n",
    "print(\"3. Weight Updates:\")\n",
    "d_error_1 = student_1_y - output_1\n",
    "updated_weights = weights + learnrate * d_error_1 * student_1_x\n",
    "updated_bias = bias + learnrate * d_error_1\n",
    "print(f\"   d_error = {student_1_y} - {output_1:.3f} = {d_error_1:.3f}\")\n",
    "print(f\"   new_weights = {weights[0]:.3f} + {learnrate} * {d_error_1:.3f} * {student_1_x[0]} = {updated_weights[0]:.3f}\")\n",
    "print(f\"   new_bias = {bias:.3f} + {learnrate} * {d_error_1:.3f} = {updated_bias:.3f}\\n\")\n",
    "\n",
    "# Update parameters for the next step\n",
    "weights, bias = updated_weights, updated_bias\n",
    "\n",
    "# Results After Step 1\n",
    "print(\"Results After Step 1:\")\n",
    "print(f\"weights = [{weights[0]:.3f}], bias = {bias:.3f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- Training Step 2: Process Student 2 ---\n",
    "print(\"###### Training Step 2: Process Student 2 ######\")\n",
    "print(f\"Processing: features = {student_2_x}, y = {student_2_y}\\n\")\n",
    "\n",
    "# Forward Pass\n",
    "print(\"1. Forward Pass:\")\n",
    "linear_combination_2 = np.dot(student_2_x, weights) + bias\n",
    "output_2 = sigmoid(linear_combination_2)\n",
    "print(f\"   linear_combination = ({student_2_x[0]} * {weights[0]:.3f}) + {bias:.3f} = {linear_combination_2:.3f}\")\n",
    "print(f\"   output = sigmoid({linear_combination_2:.3f}) = {output_2:.3f}\\n\")\n",
    "\n",
    "# Calculate Error\n",
    "print(\"2. Calculate Error:\")\n",
    "error_2 = error_formula(student_2_y, output_2)\n",
    "print(f\"   error = -{student_2_y}*log({output_2:.3f}) - (1-{student_2_y})*log(1-{output_2:.3f}) = {error_2:.3f}\\n\")\n",
    "\n",
    "# Weight Updates\n",
    "print(\"3. Weight Updates:\")\n",
    "d_error_2 = student_2_y - output_2\n",
    "updated_weights_2 = weights + learnrate * d_error_2 * student_2_x\n",
    "updated_bias_2 = bias + learnrate * d_error_2\n",
    "print(f\"   d_error = {student_2_y} - {output_2:.3f} = {d_error_2:.3f}\")\n",
    "print(f\"   new_weights = {weights[0]:.3f} + {learnrate} * {d_error_2:.3f} * {student_2_x[0]} = {updated_weights_2[0]:.3f}\")\n",
    "print(f\"   new_bias = {bias:.3f} + {learnrate} * {d_error_2:.3f} = {updated_bias_2:.3f}\\n\")\n",
    "\n",
    "# Final update\n",
    "weights, bias = updated_weights_2, updated_bias_2\n",
    "\n",
    "# Final Results After Step 2\n",
    "print(\"Final Results After Step 2:\")\n",
    "print(f\"weights = [{weights[0]:.3f}], bias = {bias:.3f}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analysis of Learning Progress\n",
    "\n",
    "**Error Reduction:**\n",
    "- Student 1 error: 1.386 (high error for failed student predicted as likely to pass)\n",
    "- Student 2 error: 0.058 (low error for passed student predicted correctly)\n",
    "\n",
    "**Weight Evolution:**\n",
    "- Initial: weight = 0.5, bias = 0.1\n",
    "- After training: weight = 0.395, bias = 0.031\n",
    "- **Interpretation**: Model learned that study hours have positive correlation with passing, but reduced the initial overconfident weight\n",
    "\n",
    "**Prediction Improvement:**\n",
    "- **Before training**: 2 hours → sigmoid(2.0 * 0.5 + 0.1) = 75% pass probability\n",
    "- **After training**: 2 hours → sigmoid(2.0 * 0.395 + 0.031) = 69.4% pass probability\n",
    "\n",
    "The model is learning to reduce overconfident predictions and adjust weights based on the error between predicted and actual outcomes. Each function call demonstrates how the gradient descent algorithm iteratively improves the model's ability to distinguish between passing and failing students."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
