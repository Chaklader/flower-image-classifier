{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Models\n",
    "\n",
    "In this notebook, I'll show you how to save and load models with PyTorch. This is important because you'll often want to load previously trained models to use in making predictions or to continue training on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper\n",
    "import fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwsAAAMLCAYAAAABpgu6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAB7CAAAewgFu0HU+AAAYNklEQVR4nO3ZTbMcB33F4X/PjOZKvpJKYIRFJdnEC7NIQrLLi9lQRaWKLJMK8BlD+ATgCin2AZk1NiHeYMoKGEvWfZnOIqRSlTosgi9nLuPn+QA63dM9rfubXtZ1XQcAAOD/2Bz7AAAAgNtJLAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAAKLdTf+DX3nzSzf9TwL8v335b96s7HzmM48qO//+059WdmZmzvZnlZ3DeqjszMw8fPCgsvPaa08qOzMz//TP36rsXF5eVnZO0bIsta11XWtb3H5vff+HN/ZvebMAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAomVd1/Um/8GvvPmlm/zngIKHDx9Wdv7x7/+hsjMzs9/vKzu7O7vKzlnpfGZmfvof71V2/ugP/6CyMzNzdX1d2Xn58qKyMzNz/sq9ys533nqrsvNvP/hBZQc+Dd76/g9v7N/yZgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEO2OfQBA9rdf/Wpt6/U/fr2ys65rZWdm5uLyorLz8uXLys6LzYvKzszMK6/cq+x88MGzys7MzLJZalst19dXlZ0vv/lmZeeLb7xR2ZmZ+c53v1vZef/nP6/swO+SNwsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEC0O/YBwO+bb37965Wdx48fV3ZmZp4/f17ZWWap7MzMbDad30KWTeec1lkrOzMz++2+srOuvXOq6d3itc+v9Xx49OhRZWdm5pvf+EZl51++96+VnZmZp28/rW3x6eLNAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAg2h37AOAm/N3Xvlbbevz4cWXnww9/VdmZmblzp/MoWA9rZWdmZm1NLb1zajmsh2Mfwu+tZV16W9PZ2mw6vyteXV5VdmZmrq+vKzt//Vd/WdmZmXn69tPaFp8u3iwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAADR7tgHADfhC689qW1dvLyo7Ox228rOzMy6dnaWzdIZmt45ATej+Xw4XB8qO+evnFd2Zmb+7E/+tLLz9EdvV3a4PbxZAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEu2MfAKftC0+eVHbu3btX2ZmZubi4qOxsll7LH9a1srOWdrqW0kpnZ2ZmnVO8TqdnWXr3REXxttvv95Wd5jPv9ddfr+w8/dHblR1uD28WAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACAaHfsA+C0PXr0qLKzbJbKzn+PdWbWde0Mzcxm6ZzU9eFQ2ZmZ2Ww6v4UsrRuieYuvxbETs07ve9t6RmyWznfpeu09H7alZ97l5WVlZ2bm1Vc/W9vi08WbBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAINod+wA4bQ8ePKjsbJalsjMzs91uKztXV1eVnabtpvPZNS2te693i/NJrMc+gJu32XR+V7y67j3zWl+ntXhDPHzwsLbFp4s3CwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACAaHfsA+C0nZ+fH/sQbtz11fWxD+HGLctS2Vlnrez8egz+V+cWr32XZqZ3j5dOab8/6wzNzHa7rexcXFxUdmZmtlu///K74c4CAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAACi3bEPgNN2tj+r7CxLr3uXZansrOta2ZmZmc4pzRxKOzO9c2op3g41xWu0lMaa39u1dVOUZvb73p8kh+bz9cRsSv8HzrhOt4U3CwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACAaHfsA+C0bbadHt1set272W47Q4fOzMzMMktlZ521sjPTO6fWDJ9Q6Tqta+8eb32dDmvrYVT8MpWuU/OZ1/K5z32utvWz99+vbfGbebMAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEu2MfAKftbL+v7CzLUtlpOhwOta3tdlvZOcXr1LJM77NbZ63sNM+ptbVZer/BrUvnOvWeRZ3zmZnZbDr3Q/Meb7l//35t62fvv1/b4jfzZgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEO2OfQCctvPz88rO9fV1ZWdm5s6u87W5urqs7MzMrOta22pZNktn6PQ+upO0ti5U6babmVnWzth66Hx2y3J6v1/WnkNFZ2dnxz4Eyk7vmwkAANwIsQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAACi3bEPgNN2//x+Zefq6qqyMzOz23W+Npvl9Fp+nbW2tcxS24L/sa4neI+XZna7bWdoZq6urjtDvduhZrvtXSduh9P7awQAALgRYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEu2MfAKft/Py8svPR848qOzMzs5RmltLQzKzrWtnZLMXfJzqndJpan13vFq9p3uNr6UK1nkXXh0NlZ2Zm2ZzgzVey3W6PfQiUebMAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIh2xz4ATttms3SG1s7MzMy6dsaW1mc3M9dX15Wd7bKt7FT1LhOfROsZUfwJbjmxm+/6uvMcmpnZbjrPoqurq8pO0yv37h37ECjzZgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIh2xz4AuBFLb2o9rJWdw+FQ2ZmZWZofILfeKd4P63S+t8va++yWpbO1dj66qmVTuk6n91Wa7c6fjp823iwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAAKLdsQ+A49hut5Wdj54/r+zM2pmpap7T0plZiye1tE4KjuTUHnvN7+xmaW2d3nOo9fcDt4c3CwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQLQ79gFwHHfPzio7m6XTo4flUNmZmdnv95Wdi4uLys7MzPXhujO0dmZmxk8hcEOWpbOzVh8Q/LZ2O386ftr47xQAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEO2OfQAcx4MHDys766yVne1mW9mZmXn3Jz+p7Jyfn1d2ZmZeffWzlZ2LlxeVnZmZZVk6Q51bvGpdSid1gp/dYT3Utpbp3OP7O/vKzgcffFDZmZl58OBBZeds3/nsZmbW0vdpf+dOZ4hbw5sFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAg2h37ADiO/f7OsQ/hRt0pns/Tt59Wdr74xhuVnZmZLzx5rbLz4sWLys7MzG7j8fbbWmap7KzLWtmZmVnWzjk1rWvn89vv95Wdi4vLys7MzC9+8cvKzmuf/3xlp+n6cDj2IVDmzQIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABDtjn0AHMedO3cqO8sslZ3N0uveD549q+zsdr6en8jamukMtb5Lvx7rzKy9c1qX07tO69o5p8PhurKz33f+X5qZefbsPys7T568Vtlp2m62xz4EyrxZAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEu2MfAMdx9+7dys6yWSo7222ve589e1bZaV2jpt22+MhZOvfeMp2drrUzU/zoTvI6HToza+l2uHvWe+b96qNfVXY2pefQzMyLjz+u7FxeXVZ2uD28WQAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAAKLdsQ+A47h3715lZ7vRo7+tFy9e1LYuLy8rO+uslZ2ZmWWW0s7p6V2lps6VWg+Hyk7T9eG6snNxcVHZmZl57733Kjt/8aU/r+zM9J55Lz9+Wdnh9vCXHAAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAg2h37ADiOzabTiYd1rexcXV1XdppeffXVYx/CjTscDrWtzdLZOUznHm9apvThVZ3edWpdpsOh89k9fvy4sjMz8/z588rOy5cvKzszM9vttrLz0fOPKjvcHt4sAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAA0e7YB8BxPHr0qLJztt9Xdl68+Liy0/Thhx/Wts7Pzys72+22sjMzs1k6v4Usy1LZmdLMyVpLO8XrtK6dk2rtXFxcVHZmZn7xy19Wdra73jPv7tlZZef+/fuVHW4PbxYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAANHu2AfAcbzzzjuVnYcPHlR23nn33cpO07e+/e1jH8KNu3v3bm1rt91WdtZ1rewsy1LZmZnpnNHMlD67puYZte69q6urys7l5WVlp+nd4v9N213nT7of/7jz9wO3hzcLAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgEgsAAAAkVgAAAAisQAAAERiAQAAiMQCAAAQiQUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAtKzruh77IAAAgNvHmwUAACASCwAAQCQWAACASCwAAACRWAAAACKxAAAARGIBAACIxAIAABCJBQAAIBILAABAJBYAAIBILAAAAJFYAAAAIrEAAABEYgEAAIjEAgAAEIkFAAAgEgsAAEAkFgAAgOi/AJ3j8V+hWTj7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 389,
       "width": 389
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a network\n",
    "\n",
    "To make things more concise here, I moved the model architecture and training code from the last part to a file called `fc_model`. Importing this, we can easily create a fully-connected network with `fc_model.Network`, and train the network using `fc_model.train`. I'll use this model (once it's trained) to demonstrate how we can save and load models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network, define the criterion and optimizer\n",
    "\n",
    "model = fc_model.Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2..  Training Loss: 1.699..  Test Loss: 0.951..  Test Accuracy: 62.2%\n",
      "Epoch: 1/2..  Training Loss: 1.007..  Test Loss: 0.775..  Test Accuracy: 68.8%\n",
      "Epoch: 1/2..  Training Loss: 0.834..  Test Loss: 0.682..  Test Accuracy: 73.7%\n",
      "Epoch: 1/2..  Training Loss: 0.803..  Test Loss: 0.665..  Test Accuracy: 74.6%\n",
      "Epoch: 1/2..  Training Loss: 0.766..  Test Loss: 0.613..  Test Accuracy: 76.0%\n",
      "Epoch: 1/2..  Training Loss: 0.709..  Test Loss: 0.593..  Test Accuracy: 77.0%\n",
      "Epoch: 1/2..  Training Loss: 0.682..  Test Loss: 0.572..  Test Accuracy: 77.8%\n",
      "Epoch: 1/2..  Training Loss: 0.657..  Test Loss: 0.581..  Test Accuracy: 77.2%\n",
      "Epoch: 1/2..  Training Loss: 0.693..  Test Loss: 0.568..  Test Accuracy: 78.1%\n",
      "Epoch: 1/2..  Training Loss: 0.653..  Test Loss: 0.550..  Test Accuracy: 79.5%\n",
      "Epoch: 1/2..  Training Loss: 0.640..  Test Loss: 0.544..  Test Accuracy: 78.7%\n",
      "Epoch: 1/2..  Training Loss: 0.625..  Test Loss: 0.541..  Test Accuracy: 81.0%\n",
      "Epoch: 1/2..  Training Loss: 0.600..  Test Loss: 0.510..  Test Accuracy: 81.6%\n",
      "Epoch: 1/2..  Training Loss: 0.619..  Test Loss: 0.521..  Test Accuracy: 81.1%\n",
      "Epoch: 1/2..  Training Loss: 0.610..  Test Loss: 0.505..  Test Accuracy: 80.9%\n",
      "Epoch: 1/2..  Training Loss: 0.597..  Test Loss: 0.499..  Test Accuracy: 81.1%\n",
      "Epoch: 1/2..  Training Loss: 0.594..  Test Loss: 0.511..  Test Accuracy: 82.0%\n",
      "Epoch: 1/2..  Training Loss: 0.598..  Test Loss: 0.512..  Test Accuracy: 81.1%\n",
      "Epoch: 1/2..  Training Loss: 0.539..  Test Loss: 0.498..  Test Accuracy: 81.7%\n",
      "Epoch: 1/2..  Training Loss: 0.567..  Test Loss: 0.506..  Test Accuracy: 81.5%\n",
      "Epoch: 1/2..  Training Loss: 0.616..  Test Loss: 0.496..  Test Accuracy: 82.4%\n",
      "Epoch: 1/2..  Training Loss: 0.561..  Test Loss: 0.485..  Test Accuracy: 82.0%\n",
      "Epoch: 1/2..  Training Loss: 0.567..  Test Loss: 0.501..  Test Accuracy: 82.4%\n",
      "Epoch: 2/2..  Training Loss: 0.551..  Test Loss: 0.501..  Test Accuracy: 82.4%\n",
      "Epoch: 2/2..  Training Loss: 0.537..  Test Loss: 0.480..  Test Accuracy: 82.4%\n",
      "Epoch: 2/2..  Training Loss: 0.549..  Test Loss: 0.495..  Test Accuracy: 82.7%\n",
      "Epoch: 2/2..  Training Loss: 0.551..  Test Loss: 0.475..  Test Accuracy: 82.8%\n",
      "Epoch: 2/2..  Training Loss: 0.549..  Test Loss: 0.466..  Test Accuracy: 83.3%\n",
      "Epoch: 2/2..  Training Loss: 0.557..  Test Loss: 0.482..  Test Accuracy: 82.4%\n",
      "Epoch: 2/2..  Training Loss: 0.537..  Test Loss: 0.510..  Test Accuracy: 81.6%\n",
      "Epoch: 2/2..  Training Loss: 0.536..  Test Loss: 0.481..  Test Accuracy: 82.8%\n",
      "Epoch: 2/2..  Training Loss: 0.518..  Test Loss: 0.460..  Test Accuracy: 82.9%\n",
      "Epoch: 2/2..  Training Loss: 0.512..  Test Loss: 0.465..  Test Accuracy: 83.4%\n",
      "Epoch: 2/2..  Training Loss: 0.545..  Test Loss: 0.456..  Test Accuracy: 83.4%\n",
      "Epoch: 2/2..  Training Loss: 0.535..  Test Loss: 0.453..  Test Accuracy: 83.3%\n",
      "Epoch: 2/2..  Training Loss: 0.537..  Test Loss: 0.448..  Test Accuracy: 83.8%\n",
      "Epoch: 2/2..  Training Loss: 0.527..  Test Loss: 0.453..  Test Accuracy: 83.9%\n",
      "Epoch: 2/2..  Training Loss: 0.539..  Test Loss: 0.488..  Test Accuracy: 81.9%\n",
      "Epoch: 2/2..  Training Loss: 0.529..  Test Loss: 0.446..  Test Accuracy: 83.5%\n",
      "Epoch: 2/2..  Training Loss: 0.558..  Test Loss: 0.458..  Test Accuracy: 83.3%\n",
      "Epoch: 2/2..  Training Loss: 0.524..  Test Loss: 0.450..  Test Accuracy: 83.6%\n",
      "Epoch: 2/2..  Training Loss: 0.534..  Test Loss: 0.471..  Test Accuracy: 82.4%\n",
      "Epoch: 2/2..  Training Loss: 0.514..  Test Loss: 0.460..  Test Accuracy: 83.0%\n",
      "Epoch: 2/2..  Training Loss: 0.523..  Test Loss: 0.450..  Test Accuracy: 83.6%\n",
      "Epoch: 2/2..  Training Loss: 0.499..  Test Loss: 0.441..  Test Accuracy: 83.6%\n",
      "Epoch: 2/2..  Training Loss: 0.506..  Test Loss: 0.439..  Test Accuracy: 84.3%\n"
     ]
    }
   ],
   "source": [
    "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading networks\n",
    "\n",
    "As you can imagine, it's impractical to train a network every time you need to use it. Instead, we can save trained networks then load them later to train more or use them for predictions.\n",
    "\n",
    "The parameters for PyTorch networks are stored in a model's `state_dict`. We can see the state dict contains the weight and bias matrices for each of our layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest thing to do is simply save the state dict with `torch.save`. For example, we can save it to a file `'checkpoint.pth'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load the state dict with `torch.load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/25m9bdqj7pv3mhbdjmv2z1w40000gn/T/ipykernel_66259/3138749330.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('checkpoint.pth')\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––\n",
    "\n",
    "### What is the `state_dict`?\n",
    "\n",
    "The `state_dict` (state dictionary) is a simple Python dictionary that maps each layer of your model to its learnable parameters (weights and biases).\n",
    "\n",
    "*   **It's NOT the model's architecture.** It doesn't know about your `forward()` method or how layers are connected.\n",
    "*   **It's ONLY the learned weights and biases.** Think of it as a snapshot of all the \"knowledge\" your model has gained during training.\n",
    "\n",
    "A `state_dict` looks like this:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'fc1.weight': tensor([...]),\n",
    "    'fc1.bias':   tensor([...]),\n",
    "    'fc2.weight': tensor([...]),\n",
    "    'fc2.bias':   tensor([...]),\n",
    "    # ... and so on for all layers\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `torch.load()` vs. `model.load_state_dict()`\n",
    "\n",
    "These two functions perform two **separate and essential steps**:\n",
    "\n",
    "1.  **`torch.load('filepath')`**: This function **reads the file from your disk**. It un-pickles the file and loads the saved object into memory. In this case, the object it loads is the `state_dict` dictionary.\n",
    "    *   **Analogy**: You're opening a blueprint file on your computer. You can now see the blueprint, but it hasn't been used to build anything yet.\n",
    "\n",
    "2.  **`model.load_state_dict(state_dict)`**: This function takes the dictionary (the `state_dict`) and **loads its contents *into* your model instance**. It goes through the dictionary, key by key, and copies the saved weights and biases into the corresponding layers of the model you've defined.\n",
    "    *   **Analogy**: You're handing the blueprint to a construction crew, who then build the house according to its specifications.\n",
    "\n",
    "### Why Do You Need Both? The Workflow\n",
    "\n",
    "Here is the standard, recommended workflow that shows why both are necessary:\n",
    "\n",
    "```python\n",
    "# 1. First, you must define and create an instance of your model architecture.\n",
    "#    The model is like an empty shell with randomly initialized weights.\n",
    "model = MyNetwork() \n",
    "\n",
    "# 2. Use torch.load() to get the dictionary of saved weights from the file.\n",
    "#    This brings the \"knowledge\" from disk into your script.\n",
    "state_dict = torch.load('checkpoint.pth')\n",
    "\n",
    "# 3. Use model.load_state_dict() to populate your empty model shell\n",
    "#    with the saved weights.\n",
    "model.load_state_dict(state_dict)\n",
    "```\n",
    "\n",
    "### The Key Takeaway: Flexibility\n",
    "\n",
    "Separating these two steps is the most flexible and recommended approach because it decouples the **model's weights** from its **architecture code**.\n",
    "\n",
    "By just saving the `state_dict`, you can:\n",
    "*   Load the weights into a slightly different model architecture.\n",
    "*   Analyze the weights without needing the original model's Python file.\n",
    "*   Share your trained model weights easily without bundling all the code.\n",
    "\n",
    "While you *can* save the entire model object (`torch.save(model, 'entire_model.pth')`), it's less flexible and can break if you refactor your code. Saving the `state_dict` is the industry standard.\n",
    "\n",
    "And to load the state dict in to the network, you do `model.load_state_dict(state_dict)`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems pretty straightforward, but as usual it's a bit more complicated. Loading the state dict works only if the model architecture is exactly the same as the checkpoint architecture. If I create a model with a different architecture, this fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this\n",
    "model = fc_model.Network(784, 10, [400, 200, 100])\n",
    "# This will throw an error because the tensor sizes are wrong!\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we need to rebuild the model exactly as it was when trained. Information about the model architecture needs to be saved in the checkpoint, along with the state dict. To do this, you build a dictionary with all the information you need to compeletely rebuild the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the checkpoint has all the necessary information to rebuild the trained model. You can easily make that a function if you want. Similarly, we can write a function to load checkpoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = fc_model.Network(checkpoint['input_size'],\n",
    "                             checkpoint['output_size'],\n",
    "                             checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/25m9bdqj7pv3mhbdjmv2z1w40000gn/T/ipykernel_66259/3142072770.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filepath)\n"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
